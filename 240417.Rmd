---
title: "Untitled"
author: "Kim Gyeong-min"
date: "2024-04-17"
output: html_document
---
* data.frame 쓰면 범주형변수도 자연스럽게 저장 가능함, 근데 data.frame은 역행렬 계산할 때 문제 생길수도
* matrix 쓰면 범주형자료 들어올때 자른 수자형자료들도 범주형으로 바뀜

```{r}
# Data
url = 'http://www.statsci.org/data/general/hills.txt'
races.table = read.table( url, header = TRUE, sep = "\t" )
n = nrow( races.table )
p = 2


y = matrix( races.table$Time )
X = cbind( "(intercept)" = rep( 1, n ),     
           distance = races.table$Distance, 
           climb = races.table$Climb )      


# beta_hat and matrix H
beta_hat = solve( t(X) %*% X ) %*% t(X) %*% y 
ord_resid = y - X %*% beta_hat
H = X %*% solve( t(X) %*% X) %*% t(X)
dim(H)


# Internally studentized residual
SSE = sum( ord_resid^2 )
sigma2_hat = SSE / ( n - ( p + 1 ) )
internal_resid = ord_resid / sqrt( sigma2_hat * ( 1 - diag(H) ) )  #### 벡터의 몫은 원소별로 해줌
dim(internal_resid)


# Externally studentized residual
external_resid = rep( 0, n )  ## c()
sigma2_hat_is = c()
beta_hat_tildes = matrix( nrow = p + 1, ncol = n)
for ( i in 1:n ){
  y_i = matrix( y[ -i ] )   ##
  X_i = X[ -i, ]
  
  beta_hat_tilde = solve( t(X_i) %*% X_i ) %*% t( X_i ) %*% y_i
  beta_hat_tildes[,i] = beta_hat_tilde 
  
  SSE_i = sum( ( y_i - X_i %*% beta_hat_tilde )^2 )
  
  sigma2_hat_i = SSE_i / ( ( n - 1 ) - ( p + 1 ) )
  sigma2_hat_is[i] = sigma2_hat_i
  
  external_resid[i] = ord_resid[i] / sqrt( sigma2_hat_i*( 1 - H[i,i] ) )
}

length(external_resid)
beta_hat_tildes




# data.frame
round(data.frame( ord_resid, internal_resid, external_resid ), 4)
# for문으로 sigma2_hat_i를 아예 벡터로 저장한후에 for문 밖으로 나와서 extrnal_resid 구할 수도 있음
```

# plot
```{r}
plot( ord_resid, external_resid, pch = 19, col = "blue" )
```


# DFFITS
```{r}
H
DFFITS = c()
for ( i in 1:n ){
  y_i = matrix( y[ -i ] )   
  X_i = X[ -i, ]
  
  beta_hat_tilde = solve( t(X_i) %*% X_i ) %*% t( X_i ) %*% y_i
  SSE_i = sum( ( y_i - X_i %*% beta_hat_tilde )^2 )
  
  sigma2_hat_i = SSE_i / ( ( n - 1 ) - ( p + 1 ) )
  
  DFFITS[i] = ( X[i,] %*% beta_hat_tilde - X[i,] %*% beta_hat ) / sqrt( sigma2_hat_i * H[i,i]  )
}

sum( abs(DFFITS) > 1 )

plot( abs(DFFITS) )
abline( h = 1, col = "red" )
```



# Cook's distance (다시)
```{r}
H
sigma2_hat

beta_hat_tildes = matrix( ncol = n, nrow = p + 1 )
for( i in 1:n ){
  y_i = matrix( y[-i] )
  X_i = X[ -i, ]
  
  beta_hat_tildes[, i] = solve( t(X_i) %*% X_i ) %*% t(X_i) %*% y_i
}

cook_dist = c()
for( i in 1:n ){
  cook_dist[i] = sum((X %*% beta_hat_tildes[,i] - X %*% beta_hat)^2) / (sigma2_hat*(p+1))
}

# Yfit = X %*% beta_hat 
# Yfit_tilde = X %*% beta_hat_tilde 얘네 둘의 차이의 제곱합이 쿡스의 분자임

plot(abs(cook_dist))
abline ( h = qf( p = 0.5, df1 = p + 1 , df2 = n - ( p + 1 ) ), col = "red" )
```















